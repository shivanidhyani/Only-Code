{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbf3a0-be8f-4e52-8111-fa669a53a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3. \n",
    "''' Write a program to read all data from CSV file with column headings.\n",
    "        +--------------+-----------+-------+\n",
    "        |Employee Name |Department |Salary |\n",
    "        +--------------+-----------+-------+\n",
    "        |         James|      Sales|   3000|\n",
    "        |       Michael|      Sales|   4600|\n",
    "        |        Robert|      Sales|   4100|\n",
    "        |         Maria|    Finance|   3000|\n",
    "        |         James|      Sales|   3000|\n",
    "        |         Scott|    Finance|   3300|\n",
    "        |           Jen|    Finance|   3900|\n",
    "        |          Jeff|  Marketing|   3000|\n",
    "        |         Kumar|  Marketing|   2000|\n",
    "        |          Saif|      Sales|   4100|\n",
    "        +--------------+-----------+-------+\n",
    "b) Add new column “Bonus” by calculating 5% of Sales Department, 3% of Marketing Department, 4% of Finance\n",
    "Department.\n",
    "c) Removing the duplicates entries by 2 ways in Pyspark.\n",
    "d) Display table by grouping up Department Names and count the total no. of employees from each department.\n",
    "e) Display table with Ascending order by “employee_name”, then descending by “salary”\n",
    "f) Crosstab display with align “department” as row, “employee_name” as column and “salary” data to filling up\n",
    "the table.\n",
    "g) Write a program to add a new column “salary_rank” by keeping rank from Highest to lowest.\n",
    "a. [let say, add 1 in “salary_rank” column for highest salary employee, then add 2 for 2nd highest salary\n",
    "employee]\n",
    "h) Display records who “employee_name” starts with alphabet “J” by use of SQL Query in Pyspark.\n",
    "i) Join the below table with the above table by “employee_name” column (only common records]:\n",
    "+-------------+---------+\n",
    "Employee Name |   Grade |\n",
    "+-------------+---------+\n",
    "|        James|       A1|\n",
    "|      Michael|       C2|\n",
    "|       Robert|       C1|\n",
    "|         Saif|       B2|\n",
    "|        Rocky|       C1|\n",
    "|          Sam|       C1|\n",
    "+-------------+---------+\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e4a0ce-505a-48af-9cf3-23ce33a2d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, expr, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6b705a-876a-431f-8ea3-936a3b12cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 13:56:48 WARN Utils: Your hostname, Shivanis-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.106 instead (on interface en0)\n",
      "24/04/22 13:56:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/22 13:56:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Assessment3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f0b1d-65d3-4013-a4ed-f30215b72549",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = [\"apple\", \"mango\", \"lemon\"]\n",
    "price = [20, 30, 10]\n",
    "qty = [2, 5, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6719002-22c9-4ff5-a438-3639e2ad8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------+\n",
      "|Fruit|Price|Quantity|\n",
      "+-----+-----+--------+\n",
      "|apple|   20|       2|\n",
      "|mango|   30|       5|\n",
      "|lemon|   10|      12|\n",
      "+-----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(zip(fruit, price, qty), [\"Fruit\", \"Price\", \"Quantity\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7387d8ec-7834-4287-b672-29d3bd99f933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------+-----------+\n",
      "|Fruit|Price|Quantity|Total Price|\n",
      "+-----+-----+--------+-----------+\n",
      "|apple|   20|       2|         40|\n",
      "|mango|   30|       5|        150|\n",
      "|lemon|   10|      12|        120|\n",
      "+-----+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Total Price\", col(\"Price\") * col(\"Quantity\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fc7fbd-f878-4230-a187-ab280f687eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.orderBy(col(\"Total Price\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c83d8-b19a-4a8d-9cba-3655c1b9a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"fruits.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9c7605-d01b-47c8-b511-c894f0e9153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------+-----------+\n",
      "|Fruit|Price|Quantity|Total Price|\n",
      "+-----+-----+--------+-----------+\n",
      "|mango|   30|       5|        150|\n",
      "|lemon|   10|      12|        120|\n",
      "|apple|   20|       2|         40|\n",
      "+-----+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f1b41-1875-4f2f-997b-b61627cbfe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
