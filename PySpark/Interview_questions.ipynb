{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bb0f0a-d83f-406e-bea2-2db09ba679b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea415be-59bd-4c3c-bc13-3c2591f977c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 01:31:58 WARN Utils: Your hostname, Shivanis-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.106 instead (on interface en0)\n",
      "24/04/24 01:31:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/24 01:31:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Interview\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068e9fb3-6ac2-4e6f-abdb-40c9250dfcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:154: DeprecationWarning: This process (pid=24482) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "| Name|          Hobbies|\n",
      "+-----+-----------------+\n",
      "|Alice|Badminton, Tennis|\n",
      "|  Bob|  Tennis, Circket|\n",
      "|Julie| Cricket, Carroms|\n",
      "+-----+-----------------+\n",
      "\n",
      "+-----+---------+\n",
      "| Name|  Hobbies|\n",
      "+-----+---------+\n",
      "|Alice|Badminton|\n",
      "|Alice|   Tennis|\n",
      "|  Bob|   Tennis|\n",
      "|  Bob|  Circket|\n",
      "|Julie|  Cricket|\n",
      "|Julie|  Carroms|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Question 1. Write a PySpark Query using below input to get below output.  #KPMG\n",
    "Input \n",
    "+-----+---------------------+\n",
    "|  Name|             Hobbies|\n",
    "+-----+---------------------+\n",
    "| Alice|  Badmintion, Tennis|\n",
    "|   Bob|     Tennis, Cricket|\n",
    "| Julie|    Cricket, Carroms|\n",
    "+-----+---------------------+\n",
    "Output\n",
    "+-----+------------+\n",
    "|  Name|    Hobbies|\n",
    "+-----+------------+\n",
    "| Alice| Badmintion|\n",
    "| Alice|     Tennis|\n",
    "|   Bob|     Tennis|\n",
    "|   Bob|    Cricket|\n",
    "| Julie|    Cricket|\n",
    "| Julie|    Carroms|\n",
    "+-----+------------+\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "data = [('Alice', 'Badminton, Tennis' ), ('Bob',  'Tennis, Circket'), ('Julie', 'Cricket, Carroms')]\n",
    "columns = [\"Name\", \"Hobbies\"]\n",
    "df1 = spark.createDataFrame(data, columns)\n",
    "df1.show()\n",
    "\n",
    "#split : In PySpark, the split() function is used to split a string column into an array of substrings based on a delimiter.\n",
    "#explode : function is used to split a column that contains an array or map type into multiple rows, with each element of the array or map occupying its own row. \n",
    "from pyspark.sql.functions import split, explode\n",
    "df1= df1.select(df1.Name, explode(split(df1.Hobbies, ',')).alias(\"Hobbies\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7fda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|City1|City2|City3|\n",
      "+-----+-----+-----+\n",
      "|  Goa|     |   AP|\n",
      "|     |   AP| NULL|\n",
      "| NULL|     | Bglu|\n",
      "+-----+-----+-----+\n",
      "\n",
      "+------+\n",
      "|Result|\n",
      "+------+\n",
      "|   Goa|\n",
      "|    AP|\n",
      "|  Bglu|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Question2. Write a PySpark Query using below input to get below output\n",
    "Input\n",
    "+-------+-------+-------+\n",
    "| City 1| City 2| City 3|\n",
    "+-------+-------+-------+\n",
    "|    Goa|       |     AP|\n",
    "|       |     AP|   null|\n",
    "|   null|       |   Bglu|\n",
    "+-------+-------+-------+\n",
    "\n",
    "Output\n",
    "+-------+\n",
    "| Result| \n",
    "+-------+\n",
    "|    Goa|\n",
    "|     AP| \n",
    "|   Bglu|\n",
    "+-------+\n",
    "\n",
    "'''\n",
    "\n",
    "df2 = data = [('Goa', '', 'AP' ), ('',  'AP', None), (None, '', 'Bglu')]\n",
    "columns = [\"City1\", \"City2\", \"City3\"]\n",
    "df2 = spark.createDataFrame(data, columns)\n",
    "df2.show()\n",
    "\n",
    "\n",
    "#coalesce : In PySpark, the coalesce() function is used to return the first non-null value among the input columns. \n",
    "#It takes multiple columns as input and returns a new column with the first non-null value from those columns.\n",
    "from pyspark.sql.functions import coalesce,when\n",
    "df2 = df2.withColumn('Result', coalesce(\n",
    "    when(df2.City1 == \"\", None).otherwise(df2.City1), \n",
    "    when(df2.City2 == \"\", None).otherwise(df2.City2), \n",
    "    when(df2.City3 == \"\", None).otherwise(df2.City3)\n",
    "    )).drop(df2.City1, df2.City2, df2.City3)\n",
    "df2.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
