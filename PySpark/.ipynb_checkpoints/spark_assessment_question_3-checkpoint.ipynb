{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbf3a0-be8f-4e52-8111-fa669a53a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3. \n",
    "''' Write a program to read all data from CSV file with column headings.\n",
    "        +--------------+-----------+-------+\n",
    "        |Employee Name |Department |Salary |\n",
    "        +--------------+-----------+-------+\n",
    "        |         James|      Sales|   3000|\n",
    "        |       Michael|      Sales|   4600|\n",
    "        |        Robert|      Sales|   4100|\n",
    "        |         Maria|    Finance|   3000|\n",
    "        |         James|      Sales|   3000|\n",
    "        |         Scott|    Finance|   3300|\n",
    "        |           Jen|    Finance|   3900|\n",
    "        |          Jeff|  Marketing|   3000|\n",
    "        |         Kumar|  Marketing|   2000|\n",
    "        |          Saif|      Sales|   4100|\n",
    "        +--------------+-----------+-------+\n",
    "b) Add new column “Bonus” by calculating 5% of Sales Department, 3% of Marketing Department, 4% of Finance\n",
    "Department.\n",
    "c) Removing the duplicates entries by 2 ways in Pyspark.\n",
    "d) Display table by grouping up Department Names and count the total no. of employees from each department.\n",
    "e) Display table with Ascending order by “employee_name”, then descending by “salary”\n",
    "f) Crosstab display with align “department” as row, “employee_name” as column and “salary” data to filling up\n",
    "the table.\n",
    "\n",
    "g) Write a program to add a new column “salary_rank” by keeping rank from Highest to lowest.\n",
    "a. [let say, add 1 in “salary_rank” column for highest salary employee, then add 2 for 2nd highest salary\n",
    "employee]\n",
    "h) Display records who “employee_name” starts with alphabet “J” by use of SQL Query in Pyspark.\n",
    "i) Join the below table with the above table by “employee_name” column (only common records]:\n",
    "+-------------+---------+\n",
    "Employee Name |   Grade |\n",
    "+-------------+---------+\n",
    "|        James|       A1|\n",
    "|      Michael|       C2|\n",
    "|       Robert|       C1|\n",
    "|         Saif|       B2|\n",
    "|        Rocky|       C1|\n",
    "|          Sam|       C1|\n",
    "+-------------+---------+\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e4a0ce-505a-48af-9cf3-23ce33a2d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, when, rank, desc, first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6b705a-876a-431f-8ea3-936a3b12cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 15:17:33 WARN Utils: Your hostname, Shivanis-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.106 instead (on interface en0)\n",
      "24/04/22 15:17:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/22 15:17:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Assessment3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f0b1d-65d3-4013-a4ed-f30215b72549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_with_header(file_path):\n",
    "    try:\n",
    "        df = spark.read.csv(file_path, header=True)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9c7605-d01b-47c8-b511-c894f0e9153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_data_df = read_csv_with_header(\"sparkassessment3.csv\")\n",
    "employee_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0f1b41-1875-4f2f-997b-b61627cbfe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|employee_name|department|salary|bonus|\n",
      "+-------------+----------+------+-----+\n",
      "|        James|     Sales|  3000|150.0|\n",
      "|      Michael|     Sales|  4600|230.0|\n",
      "|       Robert|     Sales|  4100|205.0|\n",
      "|        Maria|   Finance|  3000|120.0|\n",
      "|        James|     Sales|  3000|150.0|\n",
      "|        Scott|   Finance|  3300|132.0|\n",
      "|          Jen|   Finance|  3900|156.0|\n",
      "|         Jeff| Marketing|  3000| 90.0|\n",
      "|        Kumar| Marketing|  2000| 60.0|\n",
      "|         Saif|     Sales|  4100|205.0|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_data_df = employee_data_df.withColumn(\n",
    "    \"bonus\",\n",
    "    when(col('department') == \"Sales\", col('salary') * 0.05)\n",
    "    .when(col('department') == \"Finance\", col('salary') * 0.04)\n",
    "    .when(col('department') == \"Marketing\", col('salary') * 0.03)\n",
    "    .otherwise(lit(0))\n",
    ")\n",
    "employee_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba110989-74a7-4a27-93cc-b4de06c045c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|employee_name|department|salary|bonus|\n",
      "+-------------+----------+------+-----+\n",
      "|        James|     Sales|  3000|150.0|\n",
      "|         Jeff| Marketing|  3000| 90.0|\n",
      "|          Jen|   Finance|  3900|156.0|\n",
      "|        Kumar| Marketing|  2000| 60.0|\n",
      "|        Maria|   Finance|  3000|120.0|\n",
      "|      Michael|     Sales|  4600|230.0|\n",
      "|       Robert|     Sales|  4100|205.0|\n",
      "|         Saif|     Sales|  4100|205.0|\n",
      "|        Scott|   Finance|  3300|132.0|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_data_df = employee_data_df.dropDuplicates([\"employee_name\"])\n",
    "employee_data_df.show()\n",
    "#employee_data_df = employee_data_df.distinct()  second method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044f4108-5c1c-4481-b134-9dd9f49679f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|     Sales|    4|\n",
      "|   Finance|    3|\n",
      "| Marketing|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "department_counts = employee_data_df.groupBy(\"department\").count()\n",
    "department_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e3892e-1257-4651-a56a-df897f6d989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|employee_name|department|salary|bonus|\n",
      "+-------------+----------+------+-----+\n",
      "|        James|     Sales|  3000|150.0|\n",
      "|         Jeff| Marketing|  3000| 90.0|\n",
      "|          Jen|   Finance|  3900|156.0|\n",
      "|        Kumar| Marketing|  2000| 60.0|\n",
      "|        Maria|   Finance|  3000|120.0|\n",
      "|      Michael|     Sales|  4600|230.0|\n",
      "|       Robert|     Sales|  4100|205.0|\n",
      "|         Saif|     Sales|  4100|205.0|\n",
      "|        Scott|   Finance|  3300|132.0|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_employee_data_df = employee_data_df.orderBy(col(\"employee_name\").asc(), col(\"salary\").desc())\n",
    "sorted_employee_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ba2f74-2b30-4b7e-b220-79eba91159f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+----+-----+-----+-------+------+----+-----+\n",
      "|department|James|Jeff| Jen|Kumar|Maria|Michael|Robert|Saif|Scott|\n",
      "+----------+-----+----+----+-----+-----+-------+------+----+-----+\n",
      "|   Finance| null|null|3900| null| 3000|   null|  null|null| 3300|\n",
      "| Marketing| null|3000|null| 2000| null|   null|  null|null| null|\n",
      "|     Sales| 3000|null|null| null| null|   4600|  4100|4100| null|\n",
      "+----------+-----+----+----+-----+-----+-------+------+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salary_by_department = employee_data_df.groupBy(\"department\").pivot(\"employee_name\").agg(first(\"salary\"))\n",
    "salary_by_department.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a8358e-94d9-4b28-b3d1-7f29a303f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(col(\"salary\").desc())\n",
    "employee_data_df = employee_data_df.withColumn(\"salary_rank\", rank().over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5a108a6-ff4c-47dc-a886-d987377ab75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:24:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+-----------+\n",
      "|employee_name|department|salary|bonus|salary_rank|\n",
      "+-------------+----------+------+-----+-----------+\n",
      "|      Michael|     Sales|  4600|230.0|          1|\n",
      "|       Robert|     Sales|  4100|205.0|          2|\n",
      "|         Saif|     Sales|  4100|205.0|          2|\n",
      "|          Jen|   Finance|  3900|156.0|          4|\n",
      "|        Scott|   Finance|  3300|132.0|          5|\n",
      "|        James|     Sales|  3000|150.0|          6|\n",
      "|         Jeff| Marketing|  3000| 90.0|          6|\n",
      "|        Maria|   Finance|  3000|120.0|          6|\n",
      "|        Kumar| Marketing|  2000| 60.0|          9|\n",
      "+-------------+----------+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "569ab247-7408-461d-b828-9456ca3f17e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 15:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+-----------+\n",
      "|employee_name|department|salary|bonus|salary_rank|\n",
      "+-------------+----------+------+-----+-----------+\n",
      "|          Jen|   Finance|  3900|156.0|          4|\n",
      "|        James|     Sales|  3000|150.0|          6|\n",
      "|         Jeff| Marketing|  3000| 90.0|          6|\n",
      "+-------------+----------+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_data_df.createOrReplaceTempView(\"employee_data\")\n",
    "j_name_employees = spark.sql(\"SELECT * FROM employee_data WHERE employee_name LIKE 'J%'\")\n",
    "j_name_employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f493e46-32dd-43a2-a3fc-a08a85e3dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"James\", \"A1\"),\n",
    "    (\"Michael\", \"C2\"),\n",
    "    (\"Robert\", \"C1\"),\n",
    "    (\"Saif\", \"B2\"),\n",
    "    (\"Rocky\", \"C1\"),\n",
    "    (\"Sam\", \"C1\")\n",
    "]\n",
    "grade_df = spark.createDataFrame(data, [\"Employee_Name\", \"grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fafcec8b-00ed-4546-bf19-fd1353c25787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|Employee_Name|grade|\n",
      "+-------------+-----+\n",
      "|        James|   A1|\n",
      "|      Michael|   C2|\n",
      "|       Robert|   C1|\n",
      "|         Saif|   B2|\n",
      "|        Rocky|   C1|\n",
      "|          Sam|   C1|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a6be1a-da6d-453e-83d4-06a2d3cf2e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/04/22 15:32:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+-----------+-----+\n",
      "|employee_name|department|salary|bonus|salary_rank|grade|\n",
      "+-------------+----------+------+-----+-----------+-----+\n",
      "|        James|     Sales|  3000|150.0|          6|   A1|\n",
      "|      Michael|     Sales|  4600|230.0|          1|   C2|\n",
      "|       Robert|     Sales|  4100|205.0|          2|   C1|\n",
      "|         Saif|     Sales|  4100|205.0|          2|   B2|\n",
      "+-------------+----------+------+-----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = employee_data_df.join(\n",
    "    grade_df,\n",
    "    on=employee_data_df[\"employee_name\"] == grade_df[\"Employee_Name\"],\n",
    "    how=\"inner\").drop(grade_df[\"Employee_Name\"])\n",
    "\n",
    "joined_df.show()\n",
    "\n",
    "# # Select desired columns\n",
    "# joined_df = joined_df.select(\n",
    "#     employee_data_df[\"Employee Name\"],\n",
    "#     employee_data_df[\"Department\"],\n",
    "#     employee_data_df[\"Salary\"],\n",
    "#     employee_data_df[\"Bonus\"],\n",
    "#     employee_data_df[\"salary_rank\"],\n",
    "#     grade_data_df[\"Grade\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8e087-e1c9-4968-9aff-32f160ad691f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
